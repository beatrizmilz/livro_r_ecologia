---
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

# Análises Univariadas (modelos lineares mistos generalizados)

Você já viu aqui neste livro sobre modelos lineares, que incluem análises comuns abordadas normalmente em cursos introdutórios de Bioestatística, tais como teste *t*, regressão linear simples e múltipla, Análise de Variância (ANOVA), e Análise de Covariância (ANCOVA). Estas análises podem ser descritas pelo mesmo modelo matemático de uma equação da reta do tipo:

> Y~i~ = a + b\*x~i~ + erro

no qual o que difere uma regressão linear de uma análise de variância é a natureza do elemento x~i~, variável contínua para regressão, variável categórica no caso da ANOVA (que pode ser codificada como uma matriz *design* para desenhos de ANOVA mais complexos). Nesse sentido, o que todos esses métodos têm em comum é a variável resposta Y que é um vetor numérico contínuo. Outro elemento em comum desses métodos é a distribuição de frequência do erro. Todos os modelos lineares assumem que a distribuição do erro seja Gaussiana (ou Normal). Isso de certa forma limita o tipo de dado que pode ser usado como variável resposta por estas análises. Por exemplo, dados de contagem (e.g., riqueza e abundância de espécies), de frequência (e.g., frequência de ocorrência, porcentagem de cobertura vegetal), incidência (e.g., presença ou ausência de uma espécie) ou proporção (e.g., números de animais infectados a cada 1000 animais) não são adequados para serem utilizados como variáveis resposta em modelos lineares (também chamados de Modelos Lineares Gerais). Uma prática comum quando nossos dados não são Normais é transformar por log ou raiz quadrada. No entanto, para dados de contagem isso não é recomendado (veja O'Hara & Kotze 2010, Ives 2015, Warton 2018).

Nestes casos devemos recorrer a um conjunto de modelos chamados Modelos Lineares Generalizados (GLM). Nestes modelos, o usuário especifica a distribuição de frequência que deseja utilizar para modelar a variável resposta. Esta distribuição de frequência deve pertencer à família exponencial, que inclui a distribuição de Poisson, Gaussiana, Binomial, Binomial Negativa, Gamma, Bernoulli e Beta. Ainda é possível utilizar Cumulative Link Models para modelar dados ordinais (fatores cuja ordem dos elementos importa, tais como muito baixo, baixo, alto e muito alto). Abaixo vamos ver um pouco sobre como um GLM funciona e exemplos com cada uma destas distribuições.

## Como um GLM funciona?

Diferentemente do modelo linear que vimos anteriormente neste livro, um GLM estima os parâmetros por meio de Máxima Verossimilhança (ML) ao invés dos mínimos quadrados comuns (OLS).

Portanto, um GLM relaciona a **distribuição da variável** resposta aos **preditores lineares** por meio de uma **função de ligação**. Esta é uma ligação logarítmica (também chamada de log link) que garante que o valores ajustados são sempre não negativos. Portanto, um GLM é composto por esses 3 componentes: função de distribuição, preditor linear e função de ligação. A função de distribuição Uma hipótese sobre a distribuição da variável resposta Y~i~. Isso também define a média e a variância de Y~i~. Já a função de ligação define a relação entre o valor médio de Y~i~ e da parte sistemática. Esta é também chamada de ligação entre a média e a parte sistemática do modelo. Existem três tipos de função de ligação:

•**Identity link**, que é definido por g(µ)= μ, e modela a média ou valor esperado de Y. Usado em modelos lineares padrão.

•**Log link**, que é g(μ)=log(μ), e modela o log da média. É usado para dados de contagem (que não podem assumir valores negativos) em modelos log-linear

•**Logit link**, que é g(μ)=log[μ /(1-μ )], e é usado para dados binários e regressão logística

Logo, um modelo linear (LM) pode ser visto como um caso particular de um GLM em que utiliza distribuição Gaussiana, com identity link

## Como escolher a distribuição correta para seus dados?

### Para dados contínuos

Se Y é uma variável contínua, a sua distribuição de probabilidade deve ser normal. Nesses casos as distribuições recomendadas são a **Gaussiana (Normal) ou Gamma**. Para essas distribuições, o parâmetro de dispersão é estimado separadamente da média e é às vezes chamado de *nuisance parameter*. Uma particularidade da distribuição Gamma é que ela só aceita valores contínuos positivos.

### Para dados de contagem

Se Y é binário (e.g., vivo ou morto), a distribuição de probabilidade deve ser **binomial**.

Se Y é uma contagem (e.g., abundância ou riqueza de espécies), então a distribuição de probabilidade deve ser **Poisson ou Binomial Negativa**. Existem também as chamadas pseudo-distribuições, tais como quasi-Poisson ou quasi-Negative binomial. Falaremos delas no momento certo.

Para distribuições tais como binomial e Poisson, a variância deve ser igual à media e o parâmetro de dispersão é sempre 1. Na maioria dos dados ecológicos esse pressuposto não é cumprido, veremos estratégias para lidar com isso logo à frente.

A sfunções `Ord_plot` e `goodfit` do pacote `vcd` podem auxiliar na escolha da distribuição para dados de contagem.

# Dados de contagem: a distribuição de Poisson

Para casos em que estamos interessados em quantificar uma variável discreta, ou seja, uma variável positiva, representada sempre por números inteiros, contendo um número finito de possibilidades, devemos utilizar a **distribuição de Poisson**. Esta distribuição é peculiar por ser descrita apenas por um parâmetro livre ($\lambda$). Isso quer dizer que tanto a média quanto a variância dos dados são descritos por um único parâmetro, o que implica em dizer que a média e a variância têm de ser iguais.

Vamos ver um exemplo com dados reais.

## Exemplo 1

Os dados deste exemplo vêm [deste resumo](http://www.biofund.org.mz/wp-content/uploads/2018/11/1542620326-F1514.exxpx_%20Spatial%20patterns%20of%20road%20kills%20a%20case%20study%20in%20southern%20PortugalINTRODUCT_Postericoet2005_Final_Fernando.Pdf) e consistem de dados de mortalidade de anfíbios ao longo de uma rodovia em Portugal que liga Portalegre a Monforte no sul de Portugal (27 Km) coletados Março 1995-7 usando levantamento com carro.

#### Pergunta:

> Distância do Parque Nacional influencia o número de anfíbios mortos?

**Predições**

> Quanto mais longe do parque menos anfíbios serão mortos

**Variáveis**

-   Variável resposta

    -   Contagem total de anfíbios mortos por trecho de 500 m

### Análise

Antes de começar com a análise, vamos primeiro explorar os dados fazendo um plot.

```{r}
library(ecodados)
library(tidyverse)
library(lattice)

RK <- RoadKills ## Renomeando para facilitar

head(RK)
glimpse(RK)

xyplot(Y~X, aspect = "iso", col = 1, pch = 16, data = RK)

ggplot(RK, aes(D.PARK, TOT.N))+
       geom_point()+
  theme()

ggplot(RK, aes(D.PARK, TOT.N))+
       geom_point()+
       stat_smooth(method = "loess")
```

Relação entre as variáveis parece ser bastante não linear, mas vamos começar com um modelo simples com Poisson.

> A partir de agora vamos sempre usar uma mesma estrutura para realizar nossos exercícios de modelagem. Primeiro vamos especificar o modelo, depois realizar a diagnose, e só por último realizar inferência a partir do nosso modelo.

##### Modelagem

```{r}
mod_pois <- glm(TOT.N~D.PARK, family = poisson(link = "log"), data = RK)
```

a função `glm` funciona como o `lm` que você já conhece, ou seja, o primeiro argumento é uma fórmula, em que na parte esquerda temos a variável resposta seguida do símbolo `~` (lê-se: modelado em função de) seguido pelas variáveis preditoras. Aqui podemos usar uma ou mais variáveis e testar o seu efeito aditivo (usando o sinal de +) ou a interação entre elas (usando o sinal de \*). Um bom resumo sobre como especificar o seu modelo pode ser encontrada [aqui neste blog](https://ridiculas.wordpress.com/2012/07/23/semantica-para-descrever-modelos/). Aqui optamos por um modelo bem simples modelando a mortalidade de anfíbios apenas em função da distância com o parque.

##### Diagnose básica dos resíduos do modelo

```{r}
library(RVAideMemoire)

plotresid(mod_pois, shapiro = T)#so o plot de residuos
par(mfrow=c(2,2))
plot(mod_pois)#todos os 4 plots
par(mfrow=c(1,1))
```

Os quatro gráficos não devem ter nenhum padrão aparente. Caso haja, inclua variáveis no modelo de forma linear ou use termos quadráticos. Se houver padrão pode indicar heterogeneidade de variância. Neste caso mude a distribuição.

##### Diagnose avançada

Alguns pacotes permitem calcular outros aspectos do modelo que facilitam a diagnose, ou seja, se podemos de fato confiar nos parâmetros estimados por eles, incluindo valores de significância.

Vejamos como o pacote `DHARMa` funciona:

```{r}
library(DHARMa)
simulationOutput <- simulateResiduals(fittedModel = mod_pois, plot = T)
```

O plot claramente indica que há problema com outlier, overdispersion, e desvios de normalidade (KS test), já que todos foram significativos.

##### Detectando e lidando com overdispersion

Existem duas formas de diagnosticar overdispersion que estão implementadas na maioria dos pacotes. Aqui vamos usar novamente o pacote `performance` e `DHARMa`.

No `DHARMa` está implementado um método de aleatorização dos resíduos.

```{r}
library(performance)
testDispersion(mod_pois)#modelo tem overdispersion
check_overdispersion(mod_pois)#modelo tem overdispersion
```

Além disso, podemos fazer um teste de Chi-quadrado para o resíduo da *deviance.* Quando este resultado é significativo, como vimos na última linha acima, isso indica overdispersion.

```{r}
summary(mod_pois)
```

Na parte de baixo do output da função `summary` podemos calcular o *dispersion parameter* dividindo o residual deviance pelos graus de liberdade. Assim temos que Dispersion parameter = 390.9/50 = 7.818. Quando esse valor é próximo de 1 isso sugere que não há overdispersion. No entanto, se ele for maior que 1.5 isso sugere que o modelo sofre de overdispersion e que devemos usar outra distribuição, tal como a distribuição binomial negativa.

Além disso, podemos calcular os resíduos de Pearson (resíduos normalizados), que é basicamente a raiz quadrada da variância da variável resposta. Qualquer das duas formas de diagnosticar overdispersion pode ser usada na maioria das vezes, com exceção de dados com muitos zeros (pouca variância). Por isso devemos também testar se o nosso modelo sofre de inflação de zeros, vejamos como isso funciona no pacote `performance` :

```{r}
check_zeroinflation(mod_pois)#para diagnosticar se o modelo sofre de zero inflation
```

e no `DHARMa`

```{r}
testZeroInflation(mod_pois) # para testar se existe zero inflation
```

Tanto a função do `DHARMa` quanto do `performance` conseguiram detectar que o modelo tem problemas com overdispersion, ou sobre dispersão, mas isso não é causado pelo excesso de zeros. Como já dissemos acima, no caso da distribuição Poisson tanto a média quanto a variância são modeladas pelo mesmo parâmetro ($\lambda$). Isso faz com que esta distribuição não seja muito útil para modelar dados de contagem em que haja muita variância em torno da média. Esse infelizmente é o caso da grande maioria dos dados ecológicos.

Por estes motivos não podemos fazer inferência com este modelo porque os parâmetros estimados não são confiáveis. Mas vejamos como seria feita essa inferência.

##### Inferência

```{r}
library(MuMIn)
library(piecewiseSEM)

#---Calculando o R2 do modelo
r.squaredGLMM(mod_pois)
rsquared(mod_pois)
r2(mod_pois)

broom::glance(mod_pois)
```

Aqui temos o R^2^ do modelo.

##### Plot do modelo predito

```{r}
ggplot(RK, aes(D.PARK, TOT.N))+
       geom_point()+
       geom_smooth(method = "glm", formula = y~x, method.args = list(family ="poisson"), se=TRUE)
```

### Interpretação dos resultados

Caso pudéssemos confiar nos parâmetros deste modelo poderíamos dizer que o modelo prediz que existe de fato uma diminuição do número de atropelamentos de anfíbios à medida que nos distanciamos do parque, mas essa diminuição parece não ser linear.

### O que causa a overdispersion?

Existem dois conjuntos de causas: aparente ou real. As causas aparentes são geradas pela má especificação do modelo, tais como não inclusão de co-variáveis ou interações no modelo, presença de outliers na variável resposta, efeitos não lineares da co-variável (X2, X3...), escolha errada da função de ligação (link function). As causas reais incluem variância maior que a média, muitos zeros, agregação de observações, correlação entre observações (não independência).

### O que fazer se seu modelo tiver overdispersion?

Depois de tentar corrigir possíveis más especificações, como as listadas acima, existem duas alternativas:

1.  usar outra distribuição, tal como Binomial negativa caso o dispersion parameter seja maior que 15 ou 20; ou

2.  Usar um modelo quasi-likelihood, caso 1.5 \< dispersion \> 15.

Vejamos agora as características da distribuição Binomial negativa.

# Dados de contagem: a distribuição Binomial Negativa

Geralmente, dados de contagem em estudos ecológicos ou etnobiológicos não seguem uma distribuição Poisson, pois há muita dispersão (variância) nos dados. Logo, o pressuposto da distribuição Poisson, i.e., de que a média e variância são descrita por um mesmo parâmetro ($\lambda$) é quebrado.

Como vimos, overdispersion (ou sobredispersão) é um problema comum ao se analisar dados ecológicos e deve necessariamente ser diagnosticado no modelo. Uma maneira de lidar com esse tipo de problema é utilizar uma outra distribuição diferente da Poisson. A binomial negativa pode ser entendida como uma mistura da distibuição Poisson e Gamma, ou seja, ela aceita dados de contagem que sejam positivos, mas sem zero. A grande vantagem desta distribuição é que, diferentemente da Poisson, ela tem um parâmetro para modelar a média ($\lambda$) e outro para modelar a variância (*k*). Logo, ela permite modelar dados em que a média é diferente da variância. Vejamos um exemplo.

Aqui vamos continuar com estes dados para ver como o modelo se comporta com essa nova distribuição especificada. Para isso vamos utilizar a função `glm.nb` do pacote `MASS`:

### Análise

```{r}
library(MASS)
mod_nb <- glm.nb(TOT.N~D.PARK, data = RK)
```

##### Diagnose resíduos

Assim como fizemos com o modelo com Poisson, vamos agora diagnosticar os resíduos:

```{r}
plotresid(mod_nb, shapiro = T)
par(mfrow=c(2,2))
plot(mod_nb)
par(mfrow=c(1,1))
check_overdispersion(mod_nb)
(chat <- deviance(mod_nb) / df.residual(mod_nb))#dispersion parameter
```

É possível ver que o modelo já não tem overdispersion. O dispersion parameter é próximo de 1. Agora sim podemos levar em conta o R^2^ ...

##### Inferência

```{r}
r.squaredGLMM(mod_nb)
rsquared(mod_nb)
r2(mod_nb)
```

... e interpretar o resultado

### Interpretação dos resultados

```{r message=FALSE, warning=FALSE}
summary(mod_nb)
broom::glance(mod_nb)
```

Aqui vemos que a reta predita pelo modelo é muito similar ao que tivemos com o Poisson. No entanto, agora que sabemos que este modelo com binomial negativa foi corretamente especificada podemos confiar nos parâmetros estimados.

##### Plot do modelo predito

```{r}
ggplot(RK, aes(D.PARK, TOT.N))+
       geom_point()+
       geom_smooth(method = "glm.nb", formula = y~x, se=TRUE)
```

# Dados de contagem: modelos quasi-likelihood

Como dissemos acima, uma outra alternativa para ajustar modelos GLM a dados de contagem são os chamados "quasi-likelihood", tais como quasi-Poisson e quasi-binomial. Dependendo do valor do dispersion parameter, pode ser útil escolher este tipo de modelo. No entanto, eles vêm com uma desvantagem: não é possível calcular o valor de Akaike Information Criterion (AIC) porque estes modelos não retonam um valor de likelihood (verosimilhança). Este parâmetro é comumente utilizado em abordagens estatísticas de teoria da informação para selecionar o melhor modelo que se ajusta aos dados. Como o AIC depende do valor de likelihood, que representa o ajuste do modelo aos dados, não é possível calcular o AIC diretamente com as mesmas funções. Neste caso, precisamos utilizar outras funções disponíveis nos pacotes `MuMIn`, `AICcmodavg`, e `bbmle` para calcular o QAIC. Para mais detalhes sobre esses modelos, veja o vignette sobre o assunto do pacote `bbmle`.

### Análise

Aqui vamos apenas exemplificar como um modelo com quasi-poisson pode ser especificado.

```{r}
mod_quasipois <- glm(TOT.N~D.PARK, family = quasipoisson(link = "log"), data = RK)
```

##### Diagnose dos resíduos

```{r}
plotresid(mod_quasipois, shapiro = T)
par(mfrow=c(2,2))
plot(mod_quasipois)
par(mfrow=c(1,1))
check_overdispersion(mod_quasipois)#modelo tem overdispersion
(chat <- deviance(mod_quasipois) / df.residual(mod_quasipois))
```

Aqui vemos que o modelo apresenta overdispersion, com o dispersion parameter sendo \> 1.5 e não é recomendado seguir com a inferência a partir dele.

```{r}
summary(mod_quasipois)
broom::glance(mod_quasipois)
```

No entanto, gostaria de mostrar que de fato para este tipo de modelo o `summary` não mostra o AIC, que aparece como `NA`.

# Dados de contagem: a distribuição Binomial

Quando temos dados de proporção (e.g., número de doentes por 1000 habitantes) ou incidência (i.e., presença ou ausência), a distribuição mais adequada para modelar os dados é a distribuição binomial. No entanto, temos que especificar o modelo de acordo com o tipo dos dados no argumento `formula`. Vejamos dois exemplos:

### Análise com dados de proporção

Neste exemplo vamos ver como podemos modelar a proporção de células sanguíneas em função do tipo de tratamento. Este conjunto de dados foi coletado por [@Franco-Belussi2018a].

```{r}
library(sciplot)
library(emmeans) 
library(ecodados)
data(UV)
head(UV_cells);str(UV_cells)
```

Vamos explorar os dados para tentar entender como são as relações:

```{r}
lineplot.CI(UV, Eosinophil, Pigmentation, data=UV_cells)
```

Aqui vemos que este é um desenho experimental típico de uma 2x5 ANOVA fatorial (ou two-way ANOVA) em que temos dois tratamentos (fatores): pigmentação do girino com dois níveis (Yes e No) e Tempo de exposição com cinco níveis (controle sem UV, 6 h, 12 h, 18h e 24h de exposição à UV). Vemos que a quantitade de eusinófilos é muito maior nos girinos sem pigmentação ("albinos").

##### Modelagem

Aqui vamos usar o `cbind` no argumento `formula` para dizer que queremos modelar a contagem de ensinófilos *em relação ao número total de células, ou seja, sua proporção.* Aqui temos a contagem do número de eusinófilos (um tipo de célula da série branca do sangue) em lâminas histológicas girinos da rã-touro (*Lithobates catesbeianus*) num total de 1000 células:

```{r}
mod1<-glm(cbind(Eosinophil, Total_Cell)~UV*Pigmentation, family=binomial, data=UV_cells)
```

##### Diagnose básica dos resíduos do modelo

```{r}
par(mfrow=c(2,2))
plot(mod1)
par(mfrow=c(1,1))
```

parece que os resíduos não sofrem de heterogeneidade de variância, mas parece haver um pequeno desvio da normalidade. Vejamos o que o santo `DHARMa` nos diz:

```{r}
simulationBion <- simulateResiduals(fittedModel = mod1, plot = T)
```

Aqui já não resta dúvidas de que os resíduos deste modelo sofrem tanto com heterogeneidade de variância, quando overdispersion e problemas com outliers. Provavelmente o problema com outliers ocorreu por conta do pequeno tamanho amostral.

##### Inferência

Sabemos que o modelo não parece ser adequado para os dados, mas vamos interpretá-lo mesmo assim pra que possamos entender o output do `summary` e os contrastes entre

```{r}
summary(mod1)
anova(mod1)
```

Aqui temos tanto a tabela com os resultados por níveis dos fatores (`summary`) quanto a tabela com a Deviance que mostra os fatores e suas interações (`anova`). Vemos que nenhum fator foi significativo. Caso houvesse algum fator significativo poderíamos testar a significância de cada nível dos fatores usando contrastes, desta forma:

```{r}
pairs(emmeans(mod1, ~ UV|Pigmentation))
```

Aqui temos o valor de cada combinação de níveis dos fatores, com seu respetivo valor de contraste e o valor de P.

##### Plot do modelo predito

```{r}
ggplot(dados, aes(UV, Eosinophil)) +
geom_violin(aes(color=Pigmentation))
```

usando o `geom_violin` podemos perceber que existe uma dispersão grande nos tratamentos que utilizaram girinos sem pigmentação, muito maior do que nos tratamentos com girinos pigmentados.

### Análise com dados de incidência

Uma outra aplicação da distribuição binomial é quando temos dados de incidência, ou seja, presença ou ausência, de alguma variável. Por exemplo, presença ou ausência de uma espécie ou indivíduo num local. Neste caso a `formula` é diferente e o modelo é similar a uma regressão logística, vejamos.

Aqui vamos utilizar os dados do trabalho de [@oliveira2020] em que os autores queriam testar se a probabilidade de lagartos da espécie *Coleodactylus meridionalis* perderem (autotomizarem) a cauda aumenta com o tamanho do corpo e de acordo com o sexo dos lagartos. A hipótese deles era de que quanto maior o lagarto, maior a probabilidade de autotomia da cauda.

Vamos começar explorando os dados visualmente:

```{r}
ecodados::lagartos
ggplot(lagartos, aes(SVL, Tail_state))+
	geom_point(aes(shape=Sex, color=Sex))+
	geom_smooth(method = "glm", method.args=list(family="binomial"))
```

##### Modelagem

aqui vamos construir dois modelos com a mesma distribuição binomial, mas com dois *link function*: logit e probit. Como não temos nenhuma expectativa de qual dos dois link function é o melhor podemos fazer uma seleção de modelos

```{r}
mod_log<-glm(Tail_state~SVL*Sex, data=lagartos, family = binomial(link="logit"))
mod_pro<-glm(Tail_state~SVL*Sex, data=lagartos, family = binomial(link="probit"))
AICctab(mod_log, mod_pro, nobs=139)
```

Existe pouca diferença entre o modelo probit e logit. Como o modelo logit é mais simples vamos interpretá-lo apenas.

##### Diagnose dos resíduos do modelo

```{r}
simulationBion <- simulateResiduals(fittedModel = mod_log, plot = T)
```

##### Inferência

```{r}
library(sjPlot)
tab_model(mod_log,show.se = TRUE)

anova(mod_log, test="Chisq" )
```

Para modelos com parâmetro de dispersão conhecida (e.g., binomial e Poisson), o chi-quadrado é a estatística mais apropriada.

A interpretação dos resultados é que o tamanho de corpo (SVL) afeta negativamente a probabilidade da cauda estar intacta, ie., com o aumento do tamanho, a probabilidade da cauda permanecer intacta dimiui. A interação não foi significativa, então o efeito é independente do sexo dos lagartos.

# Dados de contagem com excesso de zeros

Quando se analisa abundância de espécies é comum que tenhamos dados com muitos zeros. Esse fenômeno pode ser causado por vários processos ecológicos, tais como locais fora do nicho da espécie, falha na detecção, amostras feitas fora do hábitat ou em locais onde não se espera encontrar a espécie. Esse tipo de dado é problemmático porque rompe com os pressupostos da distribuição Poisson e negative binomial, podendo inclusive ser uma das causas da overdispersion.

Nesses casos, temos de ajustar modelos que levam em conta esse excesso de zeros nos dados. Esses modelos são chamados de zero-inflated e hurdle models (também chamados de zero-altered models), dependendo de como o processo que causou os zeros é modelado.

Hurdle models (ou zero-altered models) modelam os dados dividindo-os em dois subconjuntos: um no qual reduzimos os dados a presença-ausência, ou seja, todos os dados maiores que 1 são transformados em 1 e usamos por exemplo uma distribuição binomial ou binomial negativa; e uma outra parte que só considera os valores positivos sem zero, utilizando uma Poisson truncada. Ao fazer isso, a distribuição truncada assume que os zeros são gerados tanto por processos ecológicos quanto erros de amostragem (ou seja, é impossível distinguir entre essas duas fontes). Portanto, esses zeros são excluídos da distribuição com dados de contagem. Nesse caso chamamos o primeiro modelo de Zero-altered Negative Binomial e o segundo de zero-altered Poisson. A interpretação dos modelos deve ser feita de forma conjunta.

Modelos com zero inflados funcionam de maneira similar, mas permitem que a distribuição Poisson contenha zeros, ou seja, *não é utilizada uma distribuição truncada*. Ao fazer isso, esta distribuição de Poisson pressupõe que os zeros foram gerados por um processo ecológico real, tal como, ausência de hábitat adequado.

Para ilustrar como podemos lidar com conjuntos de dados complexos vamos utilizar os dados coletados por [@lima2018] em que os autores registraram o número e também a incidência do parasita *Raillietiella mottae,* que é um crutáceo parasita do aparelho respiratório e intestinal de lagartos. Os autores registraram essa espécie infectando duas espécies de lagartos que ocorrem no nordeste Brasileiro e perguntarem quais os atributos de história de vida dos lagartos eram relacionados com o *load* de infecção, tais como tamanho e sexo.

```{r}
library(ecodados)
ecodados::parasitas
head(parasitas)
str(parasitas)
```

Explorando os dados

```{r}
ggplot(parasitas, aes(Raillietiella_mottae))+
  geom_density(aes(fill="red"))+
  facet_grid(Especie~Sexo)+
  theme(legend.position = "none")

ggplot(parasitas, aes(CRC, Raillietiella_mottae)) +
geom_point() +
facet_grid(Sexo~ Especie)
```

Aqui podemos ver que de fato existe um excesso de zeros principalmente na espécie *P. pollicaris*.

Quando nos deparamos com dados complexos assim, a estratégia é sempre começar com um modelo simples e depois adicionar mais parâmetros. Portanto, vamos iniciar com um modelo Poisson, mesmo sabendo que ele muito provavelmente não será adequado para modelar estes dados:

##### Modelagem

```{r}
an<-glm(Raillietiella_mottae~CRC+Sexo*Especie, data=parasitas, family="poisson")
```

##### Diagnose

Aqui vamos utilizar as funções do pacote `performance` novamente

```{r}
check_zeroinflation(an)#para diagnosticar se o modelo sofre de zero inflation
check_overdispersion(an)
```

A diagnose não só nos disse que o modelo sobre de overdispersion, como também de zero-inflation, como já esperávamos. Vejamos como então melhorar o nosso modelo para lidar com esses dois problemas. Especificamente, vamos utilizar um modelo Hurdle zero-truncated com binomial negativa, em que vamos modelar a parte de contagem com Poisson e a incidência com binomial negativa. Aqui tamos utilizar o pacote `glmmTMB` :

```{r}
mod1 <- glmmTMB(Raillietiella_mottae~CRC+Sexo*Especie,  zi=~., data=parasitas, family=truncated_nbinom2)
```

##### Diagnose

```{r}
bbmle::ICtab(an, mod1, type=c("AICc"), weights = TRUE)

check_zeroinflation(mod1)
```

Aqui vemos que o modelo foi bem sucedido e conseguiu predizer a mesma quantidade de zeros observada, fazendo com que o modelo seja suficiente para modelar esses dados. Também vemos que o modelo se ajusta bem melhor aos dados do que o modelo com distribuição Poisson.

```{r}
simulationOutput <- simulateResiduals(fittedModel = mod1, plot = T)
```

Os gráficos de diagnose do `DHARMa` são outra evidência para que o modelo seja adequado aos dados.

### Interpretação dos resultados

```{r}
summary(mod1)
```

Vemos que interação é significativa. Portanto, a influência do sexo na abundância do parasita depende conjuntamente da espécie. No entanto, o CRC só passa a ser significativo na parte do modelo binomial, ou seja, quando modelamos apenas a incidência (presença-ausência) do parasita. Poranto, o *CRC determina se o lagarto vai ou não ser infectado, mas não* *o quanto* *vai receber de parasitas*. Já tanto o sexo quanto a espécie foram significativas em ambas as partes do modelo, ou seja, esses fatores não influenciam diferentemente a infecção e a quantidade de parasitas.

```{r}
parasitas$phat <- predict(mod1, type="response")
parasitas <- parasitas[with(parasitas, order(Sexo, Especie)), ]
ggplot(parasitas, aes(x = CRC, y = phat, colour = Especie,shape = Sexo, 
									linetype = Sexo)) +
	geom_point(aes(y = Raillietiella_mottae), alpha=.5, position=position_jitter(h=.2)) +
	geom_line(size = 1) +
	labs(x = "Snout-Vent Length", y = "Abundance of Raillietiella mottae")
```

# Dados ordinais: os modelos cumulative link

Uma outra maneira de codificarmos os dados é utilizando categorias ordenadas, tais como ranques. Exemplos incluem a escala de Likert, scores, intervalos (e.g., de idade).

Para este exemplo iremos utilizar um outro conjunto de dados do artigo de [@Franco-Belussi2018a] que manipulou *in vitro* a concentração do hormonio noradrenalina (NA) nos olhos de peixes esgana-gato (*Gasterosteus aculeatus*) e avaliaram a expressão várias cores conferidas por tipos de células (cromatóforos). Aqui vamos usar os dados do efeito do NA na cor vermelha em machos. A nossa variável resposta é uma escala de intensidade de cor. Para mais detalhes veja o artigo original.

```{r}
cores <- read.csv2("https://ndownloader.figshare.com/files/10250700", h=TRUE)
head(cores)

#Filtrando dados - Red Male
redmale<- filter(cores, Sex=="M")
head(redmale)
```

Esses dados no entanto tem de ser codificados como um fator ordenado antes de entrarmos com eles no modelo.

```{r}
redmale$Animal<-factor(redmale$Animal)
redmale$Red<-factor(redmale$Red, levels = c("1", "2", "3", "4", "5"), ordered = TRUE)
str(redmale)
```

repare que a classe do objeto muda e temos agora que Red é um `Ordered factor`.

##### Modelagem

```{r}
library(ordinal)

mod3<-clmm(Red~Treatment+Time+(1|Animal), data=redmale, threshold = "equidistant")
```

##### Diagnose

Infelizmente o pacote `ordinal` não fornece métodos para lidar com modelos mistos, como o nosso. Então, montamos um modelo fixo apenas para entrar nas duas funções de diagnose. Essas duas funções `scale_test` e `nominal_test` testam a qualidade do ajuste (goodness-of-fit) do modelo, similar aos *likelihood ratio tests* só que para dados ordinais.

```{r}
assumption3 <- clm(Red~Treatment+Time, data=redmale, threshold = "equidistant")

scale_test(assumption3)
nominal_test(assumption3)
```

Parece que não há problemas com o efeito de escala do dado ordinal, mas a diagnose sugere que possa haver evidência de rompimento com o pressuposto de probabilidades proporcionais em relação ao tratamento. Esse é um pressuposto importante de modelos ordinais, os quais assumem que os efeitos de qualquer uma das variáveis explicativas são consistentes (proporcionais) ao longo de diferentes thresholds (que são as quebras entre cada par te categorias da variável resposta ordinal).

Isto provavelmente se deve ao baixo tamanho amostral. POr questão de brevidade vamos apenas ignorar este aspecto e interpretar o resultado do modelo mesmo assim. Mas se o seu modelo apresentar este problema, a solução deve ser realizar regressões logísticas separadamente.

##### Inferência

```{r}
summary(mod3)
anova(assumption3)
pairs(emmeans(mod3, ~ Treatment|Time, adjust= "tukey"))
```

Aqui vemos que tanto o tratamento quanto o tempo de exposição foram significativos.

### Interpretação dos resultados

```{r}
lineplot.CI(Time, Red, Treatment, data=redmale, cex = 1,
            xlab = "Experimental time (hours)", ylab = "Erythrophore Index (EI)", cex.lab = 1.5, x.leg = 1, y.leg = 4.2, cex.leg = 1.3, cex.axis = 1.5,
            col = c("#EE6363","#79CDCD"), pch = c(12,12), lwd = 1.5, ylim= c(0,5)) 
```

# Dados contínuos: distribuição beta

Aqui vamos utilizar como exemplo os dados do artigo de [@Franco-Belussi2018a] Os pesquisadores fizeram um experimento *in vivo* com peixes esgana-gato (*Gasterosteus aculeatus*) para testar como a coloração dos animais respondem ao fármaco ioimbina (YOH), que bloqueia a coloração típica que os machos exibem na época de acasalamento, e o tempo de exposição ao mesmo (além de um controle), num desenho de ANOVA fatorial. Como as medidas foram feitas repetidamente no mesmo animal, iremos incluir o `Animal` como um fator aleatório no modelo.

Os pesquisadores então mediram a intensidade de coloração escura em peixes machos. Esses dados são expressos em termos de porcentagem e variam continuamente de 0 a 100%. Para facilitar a modelagem e nos adequar à maneira com que a função requer os dados, vamos simplesmente dividir por 100 para que os dados variem entre 0 e 1.

Para modelar os dados vamos utilizar a função `glmmTMB`

```{r}
ecodados::fish

darknessmale<- filter(fish, Sex=="M")#Filtrando dados
fish$Animal<-factor(fish$Animal)

ggplot(rednessmale, aes(Darkness/100)) +
  geom_density(colour="red", fill="red") +
  theme(legend.position="none")
```

No histograma podemos ver que os dados de fato variam continuamente no intervalo entre 0 e 1, tendo uma distribuição notadamente bimodal.

##### Modelagem

```{r}
library(glmmTMB)
library(car)
mod2<-glmmTMB(Darkness/100~Treatment*Time+(1|Animal), family= beta_family, data=darknessmale)
```

##### Diagnose

Aqui utilizaremos o mesmo pacote `DHARMa` para realizar a diagnose do modelo:

```{r}
simulationOutput <- simulateResiduals(fittedModel = mod2, plot = T)
```

Podemos ver que o modelo não sofre de heterogeneidade de dispersão, overdispersion, nem problemas com outlier.

### Interpretação dos resultados

Agora podemos interpretar o output com confiança, vamos obter a tabela de anova em que teremos os testes de cada fator do modelo:

```{r}
Anova(mod2)
```

aqui vemos que a interação é significativa, portanto temos de interpretar os níveis do fator da combinação, fazemos isso no pacote `emmeans` colocando a barra \| :

```{r}
pairs(emmeans(mod2, ~ Treatment|Time))
```

e então podemos perceber que a diferença entre o controle e o tratado só passa a ser sifnigicativa depois de 1h de exposição.

Isso fica mais evidente quando plotamos os dados

```{r}
lineplot.CI(Time, Darkness, Treatment, data=darknessmale, cex = 1, xlab = "Experimental time (hours)", ylab = "Male body darkness (%)", cex.lab = 1, x.leg = 1, col = c("#EE6363","#79CDCD"), pch = c(12,12), lwd = 1.5)
```
